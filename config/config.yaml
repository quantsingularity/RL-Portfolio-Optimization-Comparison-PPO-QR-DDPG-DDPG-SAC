# Configuration file for RL Portfolio Optimization

# Data Configuration
data:
  start_date: "2015-01-01"
  end_date: "2024-12-31"
  train_start: "2015-01-01"
  train_end: "2022-12-31"
  test_start: "2023-01-01"
  test_end: "2024-12-31"

  # Asset Universe (25 assets across 4 asset classes)
  assets:
    equities:
      - AAPL # Apple
      - MSFT # Microsoft
      - GOOGL # Alphabet
      - AMZN # Amazon
      - TSLA # Tesla
      - JPM # JP Morgan
      - V # Visa
      - JNJ # Johnson & Johnson
      - WMT # Walmart
      - PG # Procter & Gamble

    cryptocurrencies:
      - BTC-USD # Bitcoin
      - ETH-USD # Ethereum
      - BNB-USD # Binance Coin
      - ADA-USD # Cardano
      - XRP-USD # Ripple

    commodities:
      - GC=F # Gold Futures
      - SI=F # Silver Futures
      - CL=F # Crude Oil Futures
      - NG=F # Natural Gas Futures
      - HG=F # Copper Futures

    fixed_income:
      - TLT # 20+ Year Treasury Bond ETF
      - IEF # 7-10 Year Treasury Bond ETF
      - SHY # 1-3 Year Treasury Bond ETF
      - LQD # Investment Grade Corporate Bond ETF
      - HYG # High Yield Corporate Bond ETF

  # Technical Indicators
  technical_indicators:
    - macd
    - rsi
    - cci
    - dx
    - boll_ub
    - boll_lb

  # Macroeconomic Factors
  macro_factors:
    - ^VIX # VIX Volatility Index

# Environment Configuration
environment:
  initial_amount: 1000000
  transaction_cost_pct: 0.001 # 0.1%
  slippage_coefficient: 0.05
  reward_scaling: 1.0
  hmax: 100 # Maximum shares per trade
  print_verbosity: 5

# Model Hyperparameters
models:
  ppo:
    n_steps: 2048
    batch_size: 256
    learning_rate: 0.0003
    ent_coef: 0.01
    clip_range: 0.2
    n_epochs: 10
    gae_lambda: 0.95
    max_grad_norm: 0.5
    vf_coef: 0.5
    policy_kwargs:
      net_arch: [128, 64]
      activation_fn: "relu"

  qr_ddpg:
    learning_rate_actor: 0.0001
    learning_rate_critic: 0.0003
    batch_size: 128
    buffer_size: 1000000
    tau: 0.005
    gamma: 0.99
    n_quantiles: 50
    policy_kwargs:
      net_arch: [128, 64]

  ddpg:
    learning_rate_actor: 0.0001
    learning_rate_critic: 0.0003
    batch_size: 128
    buffer_size: 1000000
    tau: 0.005
    gamma: 0.99
    policy_kwargs:
      net_arch: [128, 64]

  sac:
    learning_rate: 0.0003
    batch_size: 256
    buffer_size: 1000000
    tau: 0.005
    gamma: 0.99
    ent_coef: 0.2
    policy_kwargs:
      net_arch: [128, 64]

# Risk Management
risk:
  max_drawdown_penalty: 0.5 # Lambda coefficient
  risk_free_rate: 0.045 # 4.5% annual
  cvar_alpha: 0.05 # 5% for CVaR calculation

# Training Configuration
training:
  total_timesteps: 100000
  n_eval_episodes: 10
  eval_freq: 5000
  n_seeds: 10
  log_interval: 100

# Benchmark Strategies
benchmarks:
  - equal_weight
  - mvo
  - risk_parity
  - minimum_volatility
  - momentum

# Output Configuration
output:
  results_dir: "./results"
  models_dir: "./models"
  figures_dir: "./results/figures"
  logs_dir: "./results/logs"
